{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1462296,"sourceType":"datasetVersion","datasetId":857191}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%rm -r /kaggle/working/COCO","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import os\n\n# print(\"Setting up dataset paths...\")\n\n# # --- Define Paths ---\n# # Source paths are the read-only originals\n# source_base_path = '/kaggle/input/coco-2017-dataset/coco2017'\n\n# # Destination paths are in your writable working directory\n# dest_base_path = '/kaggle/working/COCO'\n# dest_img_path = os.path.join(dest_base_path, 'images')\n# dest_ann_path = os.path.join(dest_base_path, 'annotations')\n\n# print(f\"Original data is at: {source_base_path}\")\n# print(f\"New structure will be at: {dest_base_path}\")\n\n# # --- Create New Directory Structure ---\n# print(\"\\nCreating new parent directories...\")\n# os.makedirs(dest_img_path, exist_ok=True)\n# os.makedirs(dest_ann_path, exist_ok=True)\n\n# # --- Create Symbolic Links ---\n# # This links the entire image directories\n# print(\"Linking image directories...\")\n# os.symlink(os.path.join(source_base_path, 'train2017'), os.path.join(dest_img_path, 'train2017'))\n# os.symlink(os.path.join(source_base_path, 'val2017'), os.path.join(dest_img_path, 'val2017'))\n\n# # This links the individual annotation files\n# print(\"Linking annotation files...\")\n# os.symlink(os.path.join(source_base_path, 'annotations', 'instances_train2017.json'), os.path.join(dest_ann_path, 'instances_train2017.json'))\n# os.symlink(os.path.join(source_base_path, 'annotations', 'instances_val2017.json'), os.path.join(dest_ann_path, 'instances_val2017.json'))\n\n# print(\"\\n✅ Symbolic links created successfully!\")\n# print(\"The dataset is now accessible at /kaggle/working/COCO without using extra disk space.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git clone https://github.com/KrisnaPinasthika/SparseSwin.git","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd SparseSwin/SparseSwinDet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T21:14:40.338001Z","iopub.execute_input":"2025-07-28T21:14:40.338226Z","iopub.status.idle":"2025-07-28T21:14:40.343366Z","shell.execute_reply.started":"2025-07-28T21:14:40.338204Z","shell.execute_reply":"2025-07-28T21:14:40.342573Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/SparseSwin/SparseSwinDet\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%mkdir data/COCO","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T21:14:40.344303Z","iopub.execute_input":"2025-07-28T21:14:40.344577Z","iopub.status.idle":"2025-07-28T21:14:40.533717Z","shell.execute_reply.started":"2025-07-28T21:14:40.344550Z","shell.execute_reply":"2025-07-28T21:14:40.532812Z"}},"outputs":[{"name":"stdout","text":"mkdir: cannot create directory ‘data/COCO’: No such file or directory\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"%pwd","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# Define the absolute paths\nsource_dir = \"/kaggle/input/coco-2017-dataset/coco2017\"\ndest_dir = \"/kaggle/working/SparseSwin/SparseSwinDet/data/COCO\"\n\n# Create the target directory structure\nprint(\"Creating target directories...\")\nos.makedirs(os.path.join(dest_dir, 'images'), exist_ok=True)\nos.makedirs(os.path.join(dest_dir, 'annotations'), exist_ok=True)\n\n# Define source and destination paths for linking\nlinks = {\n    # Image Directories\n    os.path.join(source_dir, 'train2017'): os.path.join(dest_dir, 'images', 'train2017'),\n    os.path.join(source_dir, 'val2017'): os.path.join(dest_dir, 'images', 'val2017'),\n    # Annotation Files\n    os.path.join(source_dir, 'annotations', 'instances_train2017.json'): os.path.join(dest_dir, 'annotations', 'instances_train2017.json'),\n    os.path.join(source_dir, 'annotations', 'instances_val2017.json'): os.path.join(dest_dir, 'annotations', 'instances_val2017.json')\n}\n\n# Create the symbolic links\nprint(\"Creating symbolic links...\")\nfor src, dst in links.items():\n    if not os.path.exists(dst):\n        os.symlink(src, dst)\n        print(f\"Linked {dst}\")\n\nprint(\"\\n✅ Symbolic links created successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T21:14:40.535803Z","iopub.execute_input":"2025-07-28T21:14:40.536537Z","iopub.status.idle":"2025-07-28T21:14:40.546862Z","shell.execute_reply.started":"2025-07-28T21:14:40.536494Z","shell.execute_reply":"2025-07-28T21:14:40.546183Z"}},"outputs":[{"name":"stdout","text":"Creating target directories...\nCreating symbolic links...\nLinked /kaggle/working/SparseSwin/SparseSwinDet/data/COCO/images/train2017\nLinked /kaggle/working/SparseSwin/SparseSwinDet/data/COCO/images/val2017\nLinked /kaggle/working/SparseSwin/SparseSwinDet/data/COCO/annotations/instances_train2017.json\nLinked /kaggle/working/SparseSwin/SparseSwinDet/data/COCO/annotations/instances_val2017.json\n\n✅ Symbolic links created successfully.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install -r requirements.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T21:14:40.547585Z","iopub.execute_input":"2025-07-28T21:14:40.547786Z","iopub.status.idle":"2025-07-28T21:14:44.836528Z","shell.execute_reply.started":"2025-07-28T21:14:40.547769Z","shell.execute_reply":"2025-07-28T21:14:44.835721Z"}},"outputs":[{"name":"stdout","text":"Collecting tensorboardX (from -r requirements.txt (line 1))\n  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\nRequirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.0.10)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tensorboardX->-r requirements.txt (line 1)) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboardX->-r requirements.txt (line 1)) (25.0)\nRequirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX->-r requirements.txt (line 1)) (3.20.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->tensorboardX->-r requirements.txt (line 1)) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->tensorboardX->-r requirements.txt (line 1)) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->tensorboardX->-r requirements.txt (line 1)) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->tensorboardX->-r requirements.txt (line 1)) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->tensorboardX->-r requirements.txt (line 1)) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->tensorboardX->-r requirements.txt (line 1)) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->tensorboardX->-r requirements.txt (line 1)) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->tensorboardX->-r requirements.txt (line 1)) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->tensorboardX->-r requirements.txt (line 1)) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->tensorboardX->-r requirements.txt (line 1)) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->tensorboardX->-r requirements.txt (line 1)) (2024.2.0)\nDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: tensorboardX\nSuccessfully installed tensorboardX-2.6.4\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# --- 1. Install pyngrok ---\n!pip install pyngrok -q\n\n# --- 2. Authenticate ngrok ---\n# Get your free authtoken from https://dashboard.ngrok.com/get-started/your-authtoken\n# Replace 'YOUR_AUTHTOKEN' with your actual token\nAUTHTOKEN = \"30PjGsVNgUfQouVTdn2tAMMZWmJ_52C4en9LDiurdJGVgbDxz\"\n!ngrok config add-authtoken {AUTHTOKEN}\n\n# --- 3. Run TensorBoard and ngrok in the background ---\nfrom pyngrok import ngrok\nimport os\n\n# Define the log directory\nLOG_DIR = \"/kaggle/working/SparseSwin/SparseSwinDet/tensorboard/signatrix_sparseswin_coco\"\n\n# Kill any previous processes\nos.system(\"killall ngrok tensorboard\")\n\n# Start TensorBoard in the background\nos.system(f\"tensorboard --logdir {LOG_DIR} --host 0.0.0.0 --port 6006 &\")\n\n# Create the tunnel and get the public URL\npublic_url = ngrok.connect(6006)\nprint(\"=\"*50)\nprint(\"✅ TensorBoard is running on the following public URL:\")\nprint(public_url)\nprint(\"=\"*50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T21:14:44.837600Z","iopub.execute_input":"2025-07-28T21:14:44.837903Z","iopub.status.idle":"2025-07-28T21:14:52.492173Z","shell.execute_reply.started":"2025-07-28T21:14:44.837868Z","shell.execute_reply":"2025-07-28T21:14:52.491289Z"}},"outputs":[{"name":"stdout","text":"Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml                                \n","output_type":"stream"},{"name":"stderr","text":"ngrok: no process found\ntensorboard: no process found\n","output_type":"stream"},{"name":"stdout","text":"==================================================\n✅ TensorBoard is running on the following public URL:\nNgrokTunnel: \"https://1d4e20faadeb.ngrok-free.app\" -> \"http://localhost:6006\"\n==================================================\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Load the extension\n%load_ext tensorboard\n\n# Launch TensorBoard pointing to the log directory\n%tensorboard --logdir /kaggle/working/SparseSwin/SparseSwinDet/tensorboard/signatrix_sparseswin_coco","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%tensorboard --logdir /kaggle/working/SparseSwin/SparseSwinDet/tensorboard/signatrix_sparseswin_coco","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python train.py \\\n    --sparseswin_type tiny \\\n    --image_size 384 \\\n    --data_path data/COCO \\\n    --batch_size 8 \\\n    --num_epochs 10 \\\n    --test_interval 1 \\\n    --log_path /kaggle/working/SparseSwin/SparseSwinDet/tensorboard/signatrix_sparseswin_coco","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T21:14:52.493104Z","iopub.execute_input":"2025-07-28T21:14:52.493410Z"}},"outputs":[{"name":"stderr","text":"2025-07-28 21:14:54.821845: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753737295.005621     104 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753737295.058256     104 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\nNOTE: Using experimental fast data loading logic. To disable, pass\n    \"--load_fast=false\" and report issues on GitHub. More details:\n    https://github.com/tensorflow/tensorboard/issues/4784\n\nTensorBoard 2.18.0 at http://0.0.0.0:6006/ (Press CTRL+C to quit)\n","output_type":"stream"},{"name":"stdout","text":"loading annotations into memory...\nDone (t=19.74s)\ncreating index...\nindex created!\nloading annotations into memory...\nDone (t=0.69s)\ncreating index...\nindex created!\nDownloading: \"https://download.pytorch.org/models/swin_t-704ceda3.pth\" to /root/.cache/torch/hub/checkpoints/swin_t-704ceda3.pth\n100%|█████████████████████████████████████████| 108M/108M [00:00<00:00, 186MB/s]\n/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\nEpoch: 1/10. Iteration: 977/14785. Cls loss: 0.75219. Reg loss: 0.76697. Batch l","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"%cat train.py","metadata":{"trusted":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-07-28T21:11:25.602295Z","iopub.execute_input":"2025-07-28T21:11:25.603251Z","iopub.status.idle":"2025-07-28T21:11:25.731892Z","shell.execute_reply.started":"2025-07-28T21:11:25.603215Z","shell.execute_reply":"2025-07-28T21:11:25.730641Z"}},"outputs":[{"name":"stdout","text":"import os\nimport argparse\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom src.dataset import CocoDataset, Resizer, Normalizer, Augmenter, collater\nfrom src.model import SparseSwinDet \nfrom tensorboardX import SummaryWriter\nimport shutil\nimport numpy as np\nfrom tqdm.autonotebook import tqdm\n\n\ndef get_args():\n    parser = argparse.ArgumentParser(\"SparseSwin: Swin transformer with sparse transformer block\")\n    parser.add_argument(\"--sparseswin_type\", type=str, help=\"SparseSwin Type: tiny, small, or base\")\n    parser.add_argument(\"--image_size\", type=int, default=512, help=\"The common width and height for all images\")\n    parser.add_argument(\"--batch_size\", type=int, default=8, help=\"The number of images per batch\")\n    parser.add_argument(\"--lr\", type=float, default=1e-4)\n    parser.add_argument('--alpha', type=float, default=0.25)\n    parser.add_argument('--gamma', type=float, default=1.5)\n    parser.add_argument(\"--num_epochs\", type=int, default=500)\n    parser.add_argument(\"--test_interval\", type=int, default=1, help=\"Number of epoches between testing phases\")\n    parser.add_argument(\"--es_min_delta\", type=float, default=0.0,\n                        help=\"Early stopping's parameter: minimum change loss to qualify as an improvement\")\n    parser.add_argument(\"--es_patience\", type=int, default=0,\n                        help=\"Early stopping's parameter: number of epochs with no improvement after which training will be stopped. Set to 0 to disable this technique.\")\n    parser.add_argument(\"--data_path\", type=str, default=\"data/\", help=\"the root folder of dataset\")\n    parser.add_argument(\"--log_path\", type=str, default=\"tensorboard/signatrix_sparseswin_coco\")\n    parser.add_argument(\"--saved_path\", type=str, default=\"trained_models\")\n\n    args = parser.parse_args()\n    return args\n\n\ndef train(opt):\n    num_gpus = 1\n    if torch.cuda.is_available():\n        num_gpus = torch.cuda.device_count()\n        torch.cuda.manual_seed(123)\n    else:\n        torch.manual_seed(123)\n\n    training_params = {\n        \"batch_size\": opt.batch_size * num_gpus,\n        \"shuffle\": True,\n        \"drop_last\": True,\n        \"collate_fn\": collater,\n        \"num_workers\": 2\n    }\n\n    test_params = {\n        \"batch_size\": opt.batch_size,\n        \"shuffle\": False,\n        \"drop_last\": False,\n        \"collate_fn\": collater,\n        \"num_workers\": 2\n    }\n\n    training_set = CocoDataset(\n        root_dir=opt.data_path, \n        set=\"train2017\",\n        transform=transforms.Compose([Normalizer(), Augmenter(), Resizer()])\n    )\n    training_generator = DataLoader(training_set, **training_params)\n\n    test_set = CocoDataset(\n        root_dir=opt.data_path, set=\"val2017\",\n        transform=transforms.Compose([Normalizer(), Resizer()])\n    )\n    test_generator = DataLoader(test_set, **test_params)\n    \n    device = torch.device('cuda')\n    model = SparseSwinDet(\n                sparseswin_type=opt.sparseswin_type, \n                num_classes=training_set.num_classes(), \n                input_resolution=opt.image_size, \n                device=device\n            ).to(device)\n\n\n    if os.path.isdir(opt.log_path):\n        shutil.rmtree(opt.log_path)\n    os.makedirs(opt.log_path)\n\n    if not os.path.isdir(opt.saved_path):\n        os.makedirs(opt.saved_path)\n\n    writer = SummaryWriter(opt.log_path)\n    if torch.cuda.is_available():\n        model = model.cuda()\n        # model = nn.DataParallel(model)\n\n    optimizer = torch.optim.Adam(model.parameters(), opt.lr)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n\n    best_loss = 1e5\n    best_epoch = 0\n    model.train()\n\n    num_iter_per_epoch = len(training_generator)\n    for epoch in range(opt.num_epochs):\n        model.train()\n        # if torch.cuda.is_available():\n        #     model.module.freeze_bn()\n        # else:\n        #     model.freeze_bn()\n        epoch_loss = []\n        progress_bar = tqdm(training_generator)\n        for iter, data in enumerate(progress_bar):\n            # try:\n            optimizer.zero_grad()\n            if torch.cuda.is_available():\n                cls_loss, reg_loss = model([data['img'].cuda().float(), data['annot'].cuda()])\n            else:\n                cls_loss, reg_loss = model([data['img'].float(), data['annot']])\n\n            cls_loss = cls_loss.mean()\n            reg_loss = reg_loss.mean()\n\n\n            loss = cls_loss + reg_loss\n            if loss == 0:\n                continue\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n            optimizer.step()\n            epoch_loss.append(float(loss))\n            total_loss = np.mean(epoch_loss)\n\n            progress_bar.set_description(\n                'Epoch: {}/{}. Iteration: {}/{}. Cls loss: {:.5f}. Reg loss: {:.5f}. Batch loss: {:.5f} Total loss: {:.5f}'.format(\n                    epoch + 1, opt.num_epochs, iter + 1, num_iter_per_epoch, cls_loss, reg_loss, loss,\n                    total_loss))\n            writer.add_scalar('Train/Total_loss', total_loss, epoch * num_iter_per_epoch + iter)\n            writer.add_scalar('Train/Regression_loss', reg_loss, epoch * num_iter_per_epoch + iter)\n            writer.add_scalar('Train/Classfication_loss (focal loss)', cls_loss, epoch * num_iter_per_epoch + iter)\n\n            # except Exception as e:\n            #     print(e)\n            #     continue\n        scheduler.step(np.mean(epoch_loss))\n\n        if epoch % opt.test_interval == 0:\n            model.eval()\n            loss_regression_ls = []\n            loss_classification_ls = []\n            for iter, data in enumerate(test_generator):\n                with torch.no_grad():\n                    if torch.cuda.is_available():\n                        cls_loss, reg_loss = model([data['img'].cuda().float(), data['annot'].cuda()])\n                    else:\n                        cls_loss, reg_loss = model([data['img'].float(), data['annot']])\n\n                    cls_loss = cls_loss.mean()\n                    reg_loss = reg_loss.mean()\n\n                    loss_classification_ls.append(float(cls_loss))\n                    loss_regression_ls.append(float(reg_loss))\n\n            cls_loss = np.mean(loss_classification_ls)\n            reg_loss = np.mean(loss_regression_ls)\n            loss = cls_loss + reg_loss\n\n            print(\n                'Epoch: {}/{}. Classification loss: {:1.5f}. Regression loss: {:1.5f}. Total loss: {:1.5f}'.format(\n                    epoch + 1, opt.num_epochs, cls_loss, reg_loss,\n                    np.mean(loss)))\n            writer.add_scalar('Test/Total_loss', loss, epoch)\n            writer.add_scalar('Test/Regression_loss', reg_loss, epoch)\n            writer.add_scalar('Test/Classfication_loss (focal loss)', cls_loss, epoch)\n\n            if loss + opt.es_min_delta < best_loss:\n                best_loss = loss\n                best_epoch = epoch\n                torch.save(model, os.path.join(opt.saved_path, \"signatrix_sparseswin_coco.pth\"))\n\n#                 dummy_input = torch.rand(opt.batch_size, 3, opt.image_size, opt.image_size)\n#                 if torch.cuda.is_available():\n#                     dummy_input = dummy_input.cuda()\n#                 if isinstance(model, nn.DataParallel):\n#                     model.module.backbone_net.model.set_swish(memory_efficient=False)\n\n#                     torch.onnx.export(model.module, dummy_input,\n#                                         os.path.join(opt.saved_path, \"signatrix_efficientdet_coco.onnx\"),\n#                                         verbose=False)\n#                     model.module.backbone_net.model.set_swish(memory_efficient=True)\n#                 else:\n#                     model.backbone_net.model.set_swish(memory_efficient=False)\n\n#                     torch.onnx.export(model, dummy_input,\n#                                         os.path.join(opt.saved_path, \"signatrix_efficientdet_coco.onnx\"),\n#                                         verbose=False)\n#                     model.backbone_net.model.set_swish(memory_efficient=True)\n\n            # Early stopping\n            if epoch - best_epoch > opt.es_patience > 0:\n                print(\"Stop training at epoch {}. The lowest loss achieved is {}\".format(epoch, loss))\n                break\n    writer.close()\n\n\nif __name__ == \"__main__\":\n    opt = get_args()\n    train(opt)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}