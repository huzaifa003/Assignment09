{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1462296,"sourceType":"datasetVersion","datasetId":857191}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%rm -r /kaggle/working/COCO","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import os\n\n# print(\"Setting up dataset paths...\")\n\n# # --- Define Paths ---\n# # Source paths are the read-only originals\n# source_base_path = '/kaggle/input/coco-2017-dataset/coco2017'\n\n# # Destination paths are in your writable working directory\n# dest_base_path = '/kaggle/working/COCO'\n# dest_img_path = os.path.join(dest_base_path, 'images')\n# dest_ann_path = os.path.join(dest_base_path, 'annotations')\n\n# print(f\"Original data is at: {source_base_path}\")\n# print(f\"New structure will be at: {dest_base_path}\")\n\n# # --- Create New Directory Structure ---\n# print(\"\\nCreating new parent directories...\")\n# os.makedirs(dest_img_path, exist_ok=True)\n# os.makedirs(dest_ann_path, exist_ok=True)\n\n# # --- Create Symbolic Links ---\n# # This links the entire image directories\n# print(\"Linking image directories...\")\n# os.symlink(os.path.join(source_base_path, 'train2017'), os.path.join(dest_img_path, 'train2017'))\n# os.symlink(os.path.join(source_base_path, 'val2017'), os.path.join(dest_img_path, 'val2017'))\n\n# # This links the individual annotation files\n# print(\"Linking annotation files...\")\n# os.symlink(os.path.join(source_base_path, 'annotations', 'instances_train2017.json'), os.path.join(dest_ann_path, 'instances_train2017.json'))\n# os.symlink(os.path.join(source_base_path, 'annotations', 'instances_val2017.json'), os.path.join(dest_ann_path, 'instances_val2017.json'))\n\n# print(\"\\n✅ Symbolic links created successfully!\")\n# print(\"The dataset is now accessible at /kaggle/working/COCO without using extra disk space.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git clone https://github.com/KrisnaPinasthika/SparseSwin.git","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd SparseSwin/SparseSwinDet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T17:07:26.098054Z","iopub.execute_input":"2025-07-31T17:07:26.098377Z","iopub.status.idle":"2025-07-31T17:07:26.104283Z","shell.execute_reply.started":"2025-07-31T17:07:26.098352Z","shell.execute_reply":"2025-07-31T17:07:26.103453Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/SparseSwin/SparseSwinDet\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%mkdir saved_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T17:09:28.203746Z","iopub.execute_input":"2025-07-31T17:09:28.204531Z","iopub.status.idle":"2025-07-31T17:09:28.324417Z","shell.execute_reply.started":"2025-07-31T17:09:28.204496Z","shell.execute_reply":"2025-07-31T17:09:28.323612Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"%pwd","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# Define the absolute paths\nsource_dir = \"/kaggle/input/coco-2017-dataset/coco2017\"\ndest_dir = \"/kaggle/working/SparseSwin/SparseSwinDet/data/COCO\"\n\n# Create the target directory structure\nprint(\"Creating target directories...\")\nos.makedirs(os.path.join(dest_dir, 'images'), exist_ok=True)\nos.makedirs(os.path.join(dest_dir, 'annotations'), exist_ok=True)\n\n# Define source and destination paths for linking\nlinks = {\n    # Image Directories\n    os.path.join(source_dir, 'train2017'): os.path.join(dest_dir, 'images', 'train2017'),\n    os.path.join(source_dir, 'val2017'): os.path.join(dest_dir, 'images', 'val2017'),\n    # Annotation Files\n    os.path.join(source_dir, 'annotations', 'instances_train2017.json'): os.path.join(dest_dir, 'annotations', 'instances_train2017.json'),\n    os.path.join(source_dir, 'annotations', 'instances_val2017.json'): os.path.join(dest_dir, 'annotations', 'instances_val2017.json')\n}\n\n# Create the symbolic links\nprint(\"Creating symbolic links...\")\nfor src, dst in links.items():\n    if not os.path.exists(dst):\n        os.symlink(src, dst)\n        print(f\"Linked {dst}\")\n\nprint(\"\\n✅ Symbolic links created successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T17:12:07.578271Z","iopub.execute_input":"2025-07-31T17:12:07.579081Z","iopub.status.idle":"2025-07-31T17:12:07.587075Z","shell.execute_reply.started":"2025-07-31T17:12:07.579037Z","shell.execute_reply":"2025-07-31T17:12:07.586444Z"}},"outputs":[{"name":"stdout","text":"Creating target directories...\nCreating symbolic links...\nLinked /kaggle/working/SparseSwin/SparseSwinDet/data/COCO/images/train2017\nLinked /kaggle/working/SparseSwin/SparseSwinDet/data/COCO/images/val2017\nLinked /kaggle/working/SparseSwin/SparseSwinDet/data/COCO/annotations/instances_train2017.json\nLinked /kaggle/working/SparseSwin/SparseSwinDet/data/COCO/annotations/instances_val2017.json\n\n✅ Symbolic links created successfully.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!pip install -r requirements.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T17:11:23.720028Z","iopub.execute_input":"2025-07-31T17:11:23.720436Z","iopub.status.idle":"2025-07-31T17:11:27.820524Z","shell.execute_reply.started":"2025-07-31T17:11:23.720408Z","shell.execute_reply":"2025-07-31T17:11:27.819620Z"}},"outputs":[{"name":"stdout","text":"Collecting tensorboardX (from -r requirements.txt (line 1))\n  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\nRequirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.0.10)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tensorboardX->-r requirements.txt (line 1)) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboardX->-r requirements.txt (line 1)) (25.0)\nRequirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX->-r requirements.txt (line 1)) (3.20.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->tensorboardX->-r requirements.txt (line 1)) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->tensorboardX->-r requirements.txt (line 1)) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->tensorboardX->-r requirements.txt (line 1)) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->tensorboardX->-r requirements.txt (line 1)) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->tensorboardX->-r requirements.txt (line 1)) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->tensorboardX->-r requirements.txt (line 1)) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->tensorboardX->-r requirements.txt (line 1)) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->tensorboardX->-r requirements.txt (line 1)) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->tensorboardX->-r requirements.txt (line 1)) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->tensorboardX->-r requirements.txt (line 1)) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->tensorboardX->-r requirements.txt (line 1)) (2024.2.0)\nDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: tensorboardX\nSuccessfully installed tensorboardX-2.6.4\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# --- 1. Install pyngrok ---\n!pip install pyngrok -q\n\n# --- 2. Authenticate ngrok ---\n# Get your free authtoken from https://dashboard.ngrok.com/get-started/your-authtoken\n# Replace 'YOUR_AUTHTOKEN' with your actual token\nAUTHTOKEN = \"30PjGsVNgUfQouVTdn2tAMMZWmJ_52C4en9LDiurdJGVgbDxz\"\n!ngrok config add-authtoken {AUTHTOKEN}\n\n# --- 3. Run TensorBoard and ngrok in the background ---\nfrom pyngrok import ngrok\nimport os\n\n# Define the log directory\nLOG_DIR = \"/kaggle/working/SparseSwin/SparseSwinDet/tensorboard/signatrix_sparseswin_coco\"\n\n# Kill any previous processes\nos.system(\"killall ngrok tensorboard\")\n\n# Start TensorBoard in the background\nos.system(f\"tensorboard --logdir {LOG_DIR} --host 0.0.0.0 --port 6006 &\")\n\n# Create the tunnel and get the public URL\npublic_url = ngrok.connect(6006)\nprint(\"=\"*50)\nprint(\"✅ TensorBoard is running on the following public URL:\")\nprint(public_url)\nprint(\"=\"*50)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the extension\n%load_ext tensorboard\n\n# Launch TensorBoard pointing to the log directory\n%tensorboard --logdir /kaggle/working/SparseSwin/SparseSwinDet/tensorboard/signatrix_sparseswin_coco","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%tensorboard --logdir /kaggle/working/SparseSwin/SparseSwinDet/tensorboard/signatrix_sparseswin_coco","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python train.py \\\n    --sparseswin_type tiny \\\n    --image_size 384 \\\n    --data_path data/COCO \\\n    --batch_size 32 \\\n    --num_epochs 1 \\\n    --test_interval 1 \\\n    --log_path /kaggle/working/SparseSwin/SparseSwinDet/tensorboard/signatrix_sparseswin_coco \\\n    --saved_path /kaggle/working/SparseSwin/SparseSwinDet/saved_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T17:56:13.400128Z","iopub.execute_input":"2025-07-31T17:56:13.400957Z","iopub.status.idle":"2025-07-31T19:29:26.719771Z","shell.execute_reply.started":"2025-07-31T17:56:13.400926Z","shell.execute_reply":"2025-07-31T19:29:26.718839Z"}},"outputs":[{"name":"stdout","text":"loading annotations into memory...\nDone (t=15.49s)\ncreating index...\nindex created!\nloading annotations into memory...\nDone (t=0.57s)\ncreating index...\nindex created!\n/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\nEpoch: 1/1. Iteration: 3696/3696. Cls loss: 0.45798. Reg loss: 0.53219. Batch lo\nEpoch: 1/1. Classification loss: 0.44591. Regression loss: 0.53413. Total loss: 0.98004\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"!pip install torchprofile","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T19:32:30.406320Z","iopub.execute_input":"2025-07-31T19:32:30.407014Z","iopub.status.idle":"2025-07-31T19:33:39.875168Z","shell.execute_reply.started":"2025-07-31T19:32:30.406988Z","shell.execute_reply":"2025-07-31T19:33:39.874229Z"}},"outputs":[{"name":"stdout","text":"Collecting torchprofile\n  Downloading torchprofile-0.0.4-py3-none-any.whl.metadata (303 bytes)\nRequirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.11/dist-packages (from torchprofile) (1.26.4)\nRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.11/dist-packages (from torchprofile) (2.6.0+cu124)\nRequirement already satisfied: torchvision>=0.4 in /usr/local/lib/python3.11/dist-packages (from torchprofile) (0.21.0+cu124)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14->torchprofile) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14->torchprofile) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14->torchprofile) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14->torchprofile) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14->torchprofile) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14->torchprofile) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->torchprofile) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->torchprofile) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->torchprofile) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->torchprofile) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->torchprofile) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.4->torchprofile)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.4->torchprofile)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.4->torchprofile)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.4->torchprofile)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.4->torchprofile)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.4->torchprofile)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.4->torchprofile)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.4->torchprofile)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.4->torchprofile)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->torchprofile) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->torchprofile) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->torchprofile) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.4->torchprofile)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->torchprofile) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->torchprofile) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.4->torchprofile) (1.3.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.4->torchprofile) (11.2.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.4->torchprofile) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14->torchprofile) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14->torchprofile) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.14->torchprofile) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.14->torchprofile) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.14->torchprofile) (2024.2.0)\nDownloading torchprofile-0.0.4-py3-none-any.whl (7.7 kB)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchprofile\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchprofile-0.0.4\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"!pip install thop","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T19:36:34.655086Z","iopub.execute_input":"2025-07-31T19:36:34.655396Z","iopub.status.idle":"2025-07-31T19:36:37.971938Z","shell.execute_reply.started":"2025-07-31T19:36:34.655369Z","shell.execute_reply":"2025-07-31T19:36:37.971215Z"}},"outputs":[{"name":"stdout","text":"Collecting thop\n  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from thop) (2.6.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->thop) (2025.5.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->thop) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->thop) (3.0.2)\nDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\nInstalling collected packages: thop\nSuccessfully installed thop-0.1.1.post2209072238\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"%%writefile  mAP_evaluation.py\nfrom src.dataset import CocoDataset, Resizer, Normalizer\nfrom torchvision import transforms\nfrom pycocotools.cocoeval import COCOeval\nimport json\nimport torch\n\n\ndef evaluate_coco(dataset, model, threshold=0.2):\n    model.eval()\n    with torch.no_grad():\n        results = []\n        image_ids = []\n\n        for index in range(len(dataset)):\n            data = dataset[index]\n            scale = data['scale']\n            scores, labels, boxes = model(data['img'].cuda().permute(2, 0, 1).float().unsqueeze(dim=0))\n            boxes /= scale\n\n            if boxes.shape[0] > 0:\n\n                boxes[:, 2] -= boxes[:, 0]\n                boxes[:, 3] -= boxes[:, 1]\n\n                for box_id in range(boxes.shape[0]):\n                    score = float(scores[box_id])\n                    label = int(labels[box_id])\n                    box = boxes[box_id, :]\n\n                    if score < threshold:\n                        break\n\n                    image_result = {\n                        'image_id': dataset.image_ids[index],\n                        'category_id': dataset.label_to_coco_label(label),\n                        'score': float(score),\n                        'bbox': box.tolist(),\n                    }\n\n                    results.append(image_result)\n\n            # append image to list of processed images\n            image_ids.append(dataset.image_ids[index])\n\n            # print progress\n            print('{}/{}'.format(index, len(dataset)), end='\\r')\n\n        if not len(results):\n            return\n\n        # write output\n        json.dump(results, open('{}_bbox_results.json'.format(dataset.set_name), 'w'), indent=4)\n\n        # load results in COCO evaluation tool\n        coco_true = dataset.coco\n        coco_pred = coco_true.loadRes('{}_bbox_results.json'.format(dataset.set_name))\n\n        # run COCO evaluation\n        coco_eval = COCOeval(coco_true, coco_pred, 'bbox')\n        coco_eval.params.imgIds = image_ids\n        coco_eval.evaluate()\n        coco_eval.accumulate()\n        coco_eval.summarize()\n\n\nif __name__ == '__main__':\n    import torchprofile\n    import torch.nn as nn \n    \n    device = torch.device('cuda')\n    efficientdet = nn.Sequential(torch.load(\"/kaggle/working/SparseSwin/SparseSwinDet/saved_model/signatrix_sparseswin_coco.pth\", weights_only=False))\n    efficientdet.to(device)\n    \n    sample = torch.randn((1, 3, 384, 384)).to(device)\n    print(len(efficientdet(sample)))\n\n    # Use torchprofile only\n    # macs = torchprofile.profile_macs(efficientdet, sample)\n    # print(f\"GMACs: {macs * 1e-9:.2f} | GFLOPs: {macs * 2 * 1e-9:.2f}\")\n    \n    dataset_val = CocoDataset(\"/kaggle/working/SparseSwin/SparseSwinDet/data/COCO\", set='val2017',\n                              transform=transforms.Compose([Normalizer(), Resizer()]))\n    evaluate_coco(dataset_val, efficientdet)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T19:41:34.749851Z","iopub.execute_input":"2025-07-31T19:41:34.750160Z","iopub.status.idle":"2025-07-31T19:41:34.757386Z","shell.execute_reply.started":"2025-07-31T19:41:34.750132Z","shell.execute_reply":"2025-07-31T19:41:34.756537Z"}},"outputs":[{"name":"stdout","text":"Overwriting mAP_evaluation.py\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"!python mAP_evaluation.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T19:41:34.911711Z","iopub.execute_input":"2025-07-31T19:41:34.911961Z","iopub.status.idle":"2025-07-31T19:46:02.357063Z","shell.execute_reply.started":"2025-07-31T19:41:34.911932Z","shell.execute_reply":"2025-07-31T19:46:02.356299Z"}},"outputs":[{"name":"stdout","text":"3\nloading annotations into memory...\nDone (t=0.61s)\ncreating index...\nindex created!\nLoading and preparing results...\nDONE (t=0.63s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=12.86s).\nAccumulating evaluation results...\nDONE (t=2.03s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.064\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.121\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.061\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.053\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.114\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.084\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.107\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.109\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.088\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.193\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"%cat train.py","metadata":{"trusted":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-07-28T21:11:25.602295Z","iopub.execute_input":"2025-07-28T21:11:25.603251Z","iopub.status.idle":"2025-07-28T21:11:25.731892Z","shell.execute_reply.started":"2025-07-28T21:11:25.603215Z","shell.execute_reply":"2025-07-28T21:11:25.730641Z"}},"outputs":[{"name":"stdout","text":"import os\nimport argparse\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom src.dataset import CocoDataset, Resizer, Normalizer, Augmenter, collater\nfrom src.model import SparseSwinDet \nfrom tensorboardX import SummaryWriter\nimport shutil\nimport numpy as np\nfrom tqdm.autonotebook import tqdm\n\n\ndef get_args():\n    parser = argparse.ArgumentParser(\"SparseSwin: Swin transformer with sparse transformer block\")\n    parser.add_argument(\"--sparseswin_type\", type=str, help=\"SparseSwin Type: tiny, small, or base\")\n    parser.add_argument(\"--image_size\", type=int, default=512, help=\"The common width and height for all images\")\n    parser.add_argument(\"--batch_size\", type=int, default=8, help=\"The number of images per batch\")\n    parser.add_argument(\"--lr\", type=float, default=1e-4)\n    parser.add_argument('--alpha', type=float, default=0.25)\n    parser.add_argument('--gamma', type=float, default=1.5)\n    parser.add_argument(\"--num_epochs\", type=int, default=500)\n    parser.add_argument(\"--test_interval\", type=int, default=1, help=\"Number of epoches between testing phases\")\n    parser.add_argument(\"--es_min_delta\", type=float, default=0.0,\n                        help=\"Early stopping's parameter: minimum change loss to qualify as an improvement\")\n    parser.add_argument(\"--es_patience\", type=int, default=0,\n                        help=\"Early stopping's parameter: number of epochs with no improvement after which training will be stopped. Set to 0 to disable this technique.\")\n    parser.add_argument(\"--data_path\", type=str, default=\"data/\", help=\"the root folder of dataset\")\n    parser.add_argument(\"--log_path\", type=str, default=\"tensorboard/signatrix_sparseswin_coco\")\n    parser.add_argument(\"--saved_path\", type=str, default=\"trained_models\")\n\n    args = parser.parse_args()\n    return args\n\n\ndef train(opt):\n    num_gpus = 1\n    if torch.cuda.is_available():\n        num_gpus = torch.cuda.device_count()\n        torch.cuda.manual_seed(123)\n    else:\n        torch.manual_seed(123)\n\n    training_params = {\n        \"batch_size\": opt.batch_size * num_gpus,\n        \"shuffle\": True,\n        \"drop_last\": True,\n        \"collate_fn\": collater,\n        \"num_workers\": 2\n    }\n\n    test_params = {\n        \"batch_size\": opt.batch_size,\n        \"shuffle\": False,\n        \"drop_last\": False,\n        \"collate_fn\": collater,\n        \"num_workers\": 2\n    }\n\n    training_set = CocoDataset(\n        root_dir=opt.data_path, \n        set=\"train2017\",\n        transform=transforms.Compose([Normalizer(), Augmenter(), Resizer()])\n    )\n    training_generator = DataLoader(training_set, **training_params)\n\n    test_set = CocoDataset(\n        root_dir=opt.data_path, set=\"val2017\",\n        transform=transforms.Compose([Normalizer(), Resizer()])\n    )\n    test_generator = DataLoader(test_set, **test_params)\n    \n    device = torch.device('cuda')\n    model = SparseSwinDet(\n                sparseswin_type=opt.sparseswin_type, \n                num_classes=training_set.num_classes(), \n                input_resolution=opt.image_size, \n                device=device\n            ).to(device)\n\n\n    if os.path.isdir(opt.log_path):\n        shutil.rmtree(opt.log_path)\n    os.makedirs(opt.log_path)\n\n    if not os.path.isdir(opt.saved_path):\n        os.makedirs(opt.saved_path)\n\n    writer = SummaryWriter(opt.log_path)\n    if torch.cuda.is_available():\n        model = model.cuda()\n        # model = nn.DataParallel(model)\n\n    optimizer = torch.optim.Adam(model.parameters(), opt.lr)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n\n    best_loss = 1e5\n    best_epoch = 0\n    model.train()\n\n    num_iter_per_epoch = len(training_generator)\n    for epoch in range(opt.num_epochs):\n        model.train()\n        # if torch.cuda.is_available():\n        #     model.module.freeze_bn()\n        # else:\n        #     model.freeze_bn()\n        epoch_loss = []\n        progress_bar = tqdm(training_generator)\n        for iter, data in enumerate(progress_bar):\n            # try:\n            optimizer.zero_grad()\n            if torch.cuda.is_available():\n                cls_loss, reg_loss = model([data['img'].cuda().float(), data['annot'].cuda()])\n            else:\n                cls_loss, reg_loss = model([data['img'].float(), data['annot']])\n\n            cls_loss = cls_loss.mean()\n            reg_loss = reg_loss.mean()\n\n\n            loss = cls_loss + reg_loss\n            if loss == 0:\n                continue\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n            optimizer.step()\n            epoch_loss.append(float(loss))\n            total_loss = np.mean(epoch_loss)\n\n            progress_bar.set_description(\n                'Epoch: {}/{}. Iteration: {}/{}. Cls loss: {:.5f}. Reg loss: {:.5f}. Batch loss: {:.5f} Total loss: {:.5f}'.format(\n                    epoch + 1, opt.num_epochs, iter + 1, num_iter_per_epoch, cls_loss, reg_loss, loss,\n                    total_loss))\n            writer.add_scalar('Train/Total_loss', total_loss, epoch * num_iter_per_epoch + iter)\n            writer.add_scalar('Train/Regression_loss', reg_loss, epoch * num_iter_per_epoch + iter)\n            writer.add_scalar('Train/Classfication_loss (focal loss)', cls_loss, epoch * num_iter_per_epoch + iter)\n\n            # except Exception as e:\n            #     print(e)\n            #     continue\n        scheduler.step(np.mean(epoch_loss))\n\n        if epoch % opt.test_interval == 0:\n            model.eval()\n            loss_regression_ls = []\n            loss_classification_ls = []\n            for iter, data in enumerate(test_generator):\n                with torch.no_grad():\n                    if torch.cuda.is_available():\n                        cls_loss, reg_loss = model([data['img'].cuda().float(), data['annot'].cuda()])\n                    else:\n                        cls_loss, reg_loss = model([data['img'].float(), data['annot']])\n\n                    cls_loss = cls_loss.mean()\n                    reg_loss = reg_loss.mean()\n\n                    loss_classification_ls.append(float(cls_loss))\n                    loss_regression_ls.append(float(reg_loss))\n\n            cls_loss = np.mean(loss_classification_ls)\n            reg_loss = np.mean(loss_regression_ls)\n            loss = cls_loss + reg_loss\n\n            print(\n                'Epoch: {}/{}. Classification loss: {:1.5f}. Regression loss: {:1.5f}. Total loss: {:1.5f}'.format(\n                    epoch + 1, opt.num_epochs, cls_loss, reg_loss,\n                    np.mean(loss)))\n            writer.add_scalar('Test/Total_loss', loss, epoch)\n            writer.add_scalar('Test/Regression_loss', reg_loss, epoch)\n            writer.add_scalar('Test/Classfication_loss (focal loss)', cls_loss, epoch)\n\n            if loss + opt.es_min_delta < best_loss:\n                best_loss = loss\n                best_epoch = epoch\n                torch.save(model, os.path.join(opt.saved_path, \"signatrix_sparseswin_coco.pth\"))\n\n#                 dummy_input = torch.rand(opt.batch_size, 3, opt.image_size, opt.image_size)\n#                 if torch.cuda.is_available():\n#                     dummy_input = dummy_input.cuda()\n#                 if isinstance(model, nn.DataParallel):\n#                     model.module.backbone_net.model.set_swish(memory_efficient=False)\n\n#                     torch.onnx.export(model.module, dummy_input,\n#                                         os.path.join(opt.saved_path, \"signatrix_efficientdet_coco.onnx\"),\n#                                         verbose=False)\n#                     model.module.backbone_net.model.set_swish(memory_efficient=True)\n#                 else:\n#                     model.backbone_net.model.set_swish(memory_efficient=False)\n\n#                     torch.onnx.export(model, dummy_input,\n#                                         os.path.join(opt.saved_path, \"signatrix_efficientdet_coco.onnx\"),\n#                                         verbose=False)\n#                     model.backbone_net.model.set_swish(memory_efficient=True)\n\n            # Early stopping\n            if epoch - best_epoch > opt.es_patience > 0:\n                print(\"Stop training at epoch {}. The lowest loss achieved is {}\".format(epoch, loss))\n                break\n    writer.close()\n\n\nif __name__ == \"__main__\":\n    opt = get_args()\n    train(opt)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}